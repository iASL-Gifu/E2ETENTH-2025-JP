import torch
import os
import random
import numpy as np
import pygame
import time
import hydra
import torch
import matplotlib.pyplot as plt
from collections import deque

class LiDARCurvatureCNN(torch.nn.Module):
    """LiDARæ›²ç‡åˆ†é¡ç”¨ã®1D CNNãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨è«–ç”¨ï¼‰"""
    def __init__(self, num_classes, input_dim=2, dropout_rate=0.3):
        super(LiDARCurvatureCNN, self).__init__()
        
        self.num_classes = num_classes
        self.input_dim = input_dim
        
        # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯: å±€æ‰€çš„ãªç‰¹å¾´æŠ½å‡º
        self.conv1_1 = torch.nn.Conv1d(input_dim, 32, kernel_size=3, padding=1)
        self.conv1_2 = torch.nn.Conv1d(32, 32, kernel_size=3, padding=1)
        self.bn1 = torch.nn.BatchNorm1d(32)
        self.pool1 = torch.nn.MaxPool1d(2)
        
        # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯: ä¸­ç¨‹åº¦ã®ç¯„å›²ã®ç‰¹å¾´æŠ½å‡º
        self.conv2_1 = torch.nn.Conv1d(32, 64, kernel_size=5, padding=2)
        self.conv2_2 = torch.nn.Conv1d(64, 64, kernel_size=5, padding=2)
        self.bn2 = torch.nn.BatchNorm1d(64)
        self.pool2 = torch.nn.MaxPool1d(2)
        
        # ç¬¬3ãƒ–ãƒ­ãƒƒã‚¯: ã‚ˆã‚Šåºƒã„ç¯„å›²ã®ç‰¹å¾´æŠ½å‡º
        self.conv3_1 = torch.nn.Conv1d(64, 128, kernel_size=7, padding=3)
        self.conv3_2 = torch.nn.Conv1d(128, 128, kernel_size=7, padding=3)
        self.bn3 = torch.nn.BatchNorm1d(128)
        self.pool3 = torch.nn.MaxPool1d(2)
        
        # ç¬¬4ãƒ–ãƒ­ãƒƒã‚¯: å¤§åŸŸçš„ãªç‰¹å¾´æŠ½å‡º
        self.conv4_1 = torch.nn.Conv1d(128, 256, kernel_size=5, padding=2)
        self.conv4_2 = torch.nn.Conv1d(256, 256, kernel_size=5, padding=2)
        self.bn4 = torch.nn.BatchNorm1d(256)
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        self.global_avg_pool = torch.nn.AdaptiveAvgPool1d(1)
        
        # åˆ†é¡ãƒ˜ãƒƒãƒ‰
        self.classifier = torch.nn.Sequential(
            torch.nn.Linear(256, 512),
            torch.nn.ReLU(),
            torch.nn.Dropout(dropout_rate),
            torch.nn.Linear(512, 256),
            torch.nn.ReLU(),
            torch.nn.Dropout(dropout_rate),
            torch.nn.Linear(256, num_classes)
        )
        
        self.dropout = torch.nn.Dropout(dropout_rate)
        
    def forward(self, x):
        # å…¥åŠ›: (batch_size, 100, 2) -> (batch_size, 2, 100)
        x = x.transpose(1, 2)
        
        # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯
        x = torch.nn.functional.relu(self.conv1_1(x))
        x = torch.nn.functional.relu(self.bn1(self.conv1_2(x)))
        x = self.pool1(x)
        
        # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯
        x = torch.nn.functional.relu(self.conv2_1(x))
        x = torch.nn.functional.relu(self.bn2(self.conv2_2(x)))
        x = self.pool2(x)
        
        # ç¬¬3ãƒ–ãƒ­ãƒƒã‚¯
        x = torch.nn.functional.relu(self.conv3_1(x))
        x = torch.nn.functional.relu(self.bn3(self.conv3_2(x)))
        x = self.pool3(x)
        
        # ç¬¬4ãƒ–ãƒ­ãƒƒã‚¯
        x = torch.nn.functional.relu(self.conv4_1(x))
        x = torch.nn.functional.relu(self.bn4(self.conv4_2(x)))
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ç‰¹å¾´æŠ½å‡º
        x = self.global_avg_pool(x)
        x = x.squeeze(-1)
        
        # åˆ†é¡
        x = self.classifier(x)
        
        return x
    
    
    
class F1TenthLiDARInferenceEngine:
    """F1Tenthç’°å¢ƒç”¨ã®LiDARæ›²ç‡åˆ†é¡æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, model_path=None, device='cuda'):
        """
        æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        
        Args:
            model_path: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œç´¢ï¼‰
            device: ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹
        """
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®è‡ªå‹•æ¤œç´¢
        if model_path is None:
            model_path = self._find_latest_model()
        
        self.model_path = model_path
        
        # ãƒ¢ãƒ‡ãƒ«ã¨æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
        self.model, self.model_info = self._load_model()
        
        # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å–å¾—
        self.label_mapping = self.model_info.get('label_mapping', {})
        self.reverse_label_mapping = {v: k for k, v in self.label_mapping.items()}
        
        # çµ±è¨ˆæƒ…å ±ã®åˆæœŸåŒ–
        self.prediction_history = deque(maxlen=100)  # æœ€æ–°100äºˆæ¸¬ã‚’ä¿æŒ
        self.class_counts = {i: 0 for i in range(self.model.num_classes)}
        self.total_predictions = 0
        
        print(f"ğŸ¯ F1Tenth LiDAR Inference Engine Initialized!")
        print(f"   ğŸ“± Device: {self.device}")
        print(f"   ğŸ“„ Model: {os.path.basename(self.model_path)}")
        print(f"   ğŸ¯ Classes: {self.model.num_classes}")
        print(f"   ğŸ·ï¸ Label mapping: {self.label_mapping}")
    
    def _find_latest_model(self, model_dir='./models'):
        """æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        import glob
        
        if not os.path.exists(model_dir):
            raise FileNotFoundError(f"Model directory not found: {model_dir}")
        
        model_files = glob.glob(os.path.join(model_dir, "lidar_curvature_model_*.pth"))
        
        if not model_files:
            raise FileNotFoundError(f"No model files found in {model_dir}")
        
        # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™
        latest_model = sorted(model_files, reverse=True)[0]
        print(f"ğŸ“ Auto-selected model: {os.path.basename(latest_model)}")
        return latest_model
    
    def _load_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ï¼ˆPyTorch 2.6å¯¾å¿œï¼‰
        try:
            # å®‰å…¨ãªã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚’è¿½åŠ ã—ã¦ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
            safe_globals = [
                'numpy._core.multiarray.scalar',
                'numpy.core.multiarray.scalar',
                'numpy.dtype',
                'numpy.ndarray',
                'builtins.dict',
                'builtins.list',
                'builtins.tuple',
                'builtins.int',
                'builtins.float',
                'builtins.str',
                'builtins.bool'
            ]
            
            # å®‰å…¨ãªã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨
            with torch.serialization.safe_globals(safe_globals):
                checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=True)
                print(f"   âœ… Model loaded with secure settings")
            
        except Exception as e1:
            try:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šãŒå³ã—ã„å ´åˆã¯ã€ä¿¡é ¼ã§ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã¿
                print(f"   ğŸ”’ Using fallback loading method for trusted model file...")
                checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=False)
                print(f"   âœ… Model loaded with fallback method")
                
            except Exception as e2:
                raise RuntimeError(f"Failed to load model with both secure and fallback methods.\n"
                                 f"Secure error: {e1}\n"
                                 f"Fallback error: {e2}")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        num_classes = checkpoint['num_classes']
        model_config = checkpoint.get('model_config', {})
        
        model = LiDARCurvatureCNN(
            num_classes=num_classes,
            input_dim=model_config.get('input_dim', 2),
            dropout_rate=model_config.get('dropout_rate', 0.3)
        )
        
        # é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        return model, checkpoint
    
    def convert_f1tenth_scan_to_xy(self, scan_data, angle_min=-2.35, angle_max=2.35):
        """
        F1Tenthã®LiDARã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆè·é›¢ï¼‰ã‚’XYåº§æ¨™ã«å¤‰æ›
        
        Args:
            scan_data: F1Tenthã®LiDARã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆè·é›¢ã®é…åˆ—ï¼‰
            angle_min: æœ€å°è§’åº¦ï¼ˆãƒ©ã‚¸ã‚¢ãƒ³ï¼‰
            angle_max: æœ€å¤§è§’åº¦ï¼ˆãƒ©ã‚¸ã‚¢ãƒ³ï¼‰
        
        Returns:
            xy_data: (N, 2) ã®XYåº§æ¨™ãƒ‡ãƒ¼ã‚¿
        """
        # è§’åº¦ã®ç”Ÿæˆ
        num_points = len(scan_data)
        angles = np.linspace(angle_min, angle_max, num_points)
        
        # ç„¡åŠ¹ãªå€¤ï¼ˆinf, nanï¼‰ã‚’å‡¦ç†
        valid_mask = np.isfinite(scan_data) & (scan_data > 0)
        scan_data = np.where(valid_mask, scan_data, 10.0)  # ç„¡åŠ¹å€¤ã¯10mã«è¨­å®š
        
        # æ¥µåº§æ¨™ã‹ã‚‰XYåº§æ¨™ã«å¤‰æ›
        x = scan_data * np.cos(angles)
        y = scan_data * np.sin(angles)
        
        # XYåº§æ¨™ã‚’çµåˆ
        xy_data = np.column_stack([x, y])
        
        return xy_data
    
    def preprocess_f1tenth_lidar(self, scan_data):
        """
        F1Tenthã®LiDARãƒ‡ãƒ¼ã‚¿ã‚’æ¨è«–ç”¨ã«å‰å‡¦ç†
        
        Args:
            scan_data: F1Tenthã®LiDARã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            processed_data: æ¨è«–ç”¨Tensor (1, 100, 2)
        """
        # ã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’XYåº§æ¨™ã«å¤‰æ›
        xy_data = self.convert_f1tenth_scan_to_xy(scan_data)
        
        # 100ç‚¹ã«ãªã‚‹ã‚ˆã†ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if len(xy_data) != 100:
            # ç·šå½¢è£œé–“ã§ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            indices = np.linspace(0, len(xy_data) - 1, 100)
            x_interp = np.interp(indices, np.arange(len(xy_data)), xy_data[:, 0])
            y_interp = np.interp(indices, np.arange(len(xy_data)), xy_data[:, 1])
            xy_data = np.column_stack([x_interp, y_interp])
        
        # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ã—ã¦ Tensor ã«å¤‰æ›
        xy_data = xy_data.reshape(1, 100, 2)
        return torch.FloatTensor(xy_data).to(self.device)
    
    def predict_realtime(self, scan_data, return_probabilities=True):
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–
        
        Args:
            scan_data: F1Tenthã®LiDARã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿
            return_probabilities: ç¢ºç‡ã‚’è¿”ã™ã‹ã©ã†ã‹
        
        Returns:
            result: æ¨è«–çµæœã®è¾æ›¸
        """
        # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        processed_data = self.preprocess_f1tenth_lidar(scan_data)
        
        # æ¨è«–å®Ÿè¡Œ
        with torch.no_grad():
            outputs = self.model(processed_data)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            predicted_class = torch.argmax(outputs, dim=1).cpu().item()
            confidence = probabilities[0, predicted_class].cpu().item()
            
            # å…ƒã®ãƒ©ãƒ™ãƒ«ã«å¤‰æ›
            original_label = self.reverse_label_mapping.get(predicted_class, predicted_class)
        
        # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
        self.prediction_history.append({
            'class': predicted_class,
            'confidence': confidence,
            'timestamp': time.time()
        })
        self.class_counts[predicted_class] += 1
        self.total_predictions += 1
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        result = {
            'predicted_class': predicted_class,
            'original_label': original_label,
            'confidence': confidence,
            'probabilities': probabilities[0].cpu().numpy() if return_probabilities else None,
            'raw_outputs': outputs[0].cpu().numpy()
        }
        
        return result
    
    def get_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if self.total_predictions == 0:
            return {}
        
        # æœ€è¿‘ã®äºˆæ¸¬ã®å¹³å‡ä¿¡é ¼åº¦
        recent_confidences = [p['confidence'] for p in self.prediction_history]
        avg_confidence = np.mean(recent_confidences) if recent_confidences else 0
        
        # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ
        class_distribution = {}
        for class_idx, count in self.class_counts.items():
            percentage = count / self.total_predictions * 100
            class_distribution[class_idx] = {
                'count': count,
                'percentage': percentage
            }
        
        return {
            'total_predictions': self.total_predictions,
            'average_confidence': avg_confidence,
            'class_distribution': class_distribution,
            'recent_predictions': len(self.prediction_history)
        }
    
    def visualize_realtime_stats(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆã®å¯è¦–åŒ–"""
        stats = self.get_statistics()
        
        if stats['total_predictions'] == 0:
            return
        
        # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®è¡¨ç¤º
        print(f"\nğŸ“Š Real-time Statistics (Total: {stats['total_predictions']})")
        print(f"   Average Confidence: {stats['average_confidence']:.3f}")
        print(f"   Class Distribution:")
        
        for class_idx, dist in stats['class_distribution'].items():
            orig_label = self.reverse_label_mapping.get(class_idx, class_idx)
            print(f"     Class {class_idx} (orig: {orig_label}): {dist['count']} ({dist['percentage']:.1f}%)")


class StabilizedLiDARInference:
    """
    5ã‚¹ãƒ†ãƒƒãƒ—é€£ç¶šã§åŒã˜ã‚¯ãƒ©ã‚¹ãŒäºˆæ¸¬ã•ã‚ŒãŸå ´åˆã®ã¿æ›´æ–°ã™ã‚‹LiDARæ¨è«–ã®å®‰å®šåŒ–ã‚¯ãƒ©ã‚¹

    """


    def convert_scan(self, scans, scan_range: float=30.0):
        scans = scans / scan_range
        scans = np.clip(scans, 0, 1)
        return scans    
    def __init__(self, inference_engine, stability_window=5):
        """
        Args:
            inference_engine: F1TenthLiDARInferenceEngine ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            stability_window: å®‰å®šåŒ–ã®ãŸã‚ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
        """
        self.inference_engine = inference_engine
        self.stability_window = stability_window
        
        # éå»ã®äºˆæ¸¬çµæœã‚’ä¿æŒ
        self.prediction_history = deque(maxlen=stability_window)
        
        # ç¾åœ¨ã®å®‰å®šã—ãŸã‚¯ãƒ©ã‚¹
        self.stable_class = None
        self.stable_confidence = 0.0
        self.stable_result = None
        
        # çµ±è¨ˆæƒ…å ±
        self.total_predictions = 0
        self.stable_updates = 0
        self.last_update_step = 0
        
        print(f"ğŸ¯ Stabilized LiDAR Inference initialized with {stability_window}-step window")
    
    def predict_and_stabilize(self, scan_data, current_step=None):
        """
        LiDARæ¨è«–ã‚’å®Ÿè¡Œã—ã€å®‰å®šæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦å¿…è¦ã«å¿œã˜ã¦æ›´æ–°
        
        Args:
            scan_data: LiDARã‚¹ã‚­ãƒ£ãƒ³ãƒ‡ãƒ¼ã‚¿
            current_step: ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼ˆçµ±è¨ˆç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            dict: {
                'inference_result': æœ€æ–°ã®æ¨è«–çµæœ,
                'stable_result': å®‰å®šã—ãŸæ¨è«–çµæœï¼ˆæ›´æ–°ã•ã‚ŒãŸå ´åˆï¼‰,
                'is_updated': å®‰å®šã—ãŸçµæœãŒæ›´æ–°ã•ã‚ŒãŸã‹ã©ã†ã‹,
                'stability_info': å®‰å®šæ€§ã«é–¢ã™ã‚‹æƒ…å ±
            }
        """
        # æœ€æ–°ã®æ¨è«–ã‚’å®Ÿè¡Œ
        
        scan_data=self.convert_scan(scan_data)
        inference_result = self.inference_engine.predict_realtime(scan_data)
        predicted_class = inference_result['predicted_class']
        confidence = inference_result['confidence']
        
        # äºˆæ¸¬å±¥æ­´ã«è¿½åŠ 
        self.prediction_history.append({
            'class': predicted_class,
            'confidence': confidence,
            'step': current_step
        })
        
        self.total_predictions += 1
        
        # å®‰å®šæ€§ã‚’ãƒã‚§ãƒƒã‚¯
        is_stable, stability_info = self._check_stability()
        is_updated = False
        
        if is_stable:
            # å®‰å®šã—ãŸã‚¯ãƒ©ã‚¹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿æ›´æ–°
            if self.stable_class != predicted_class:
                self.stable_class = predicted_class
                self.stable_confidence = confidence
                self.stable_result = inference_result.copy()
                self.stable_updates += 1
                self.last_update_step = current_step if current_step else self.total_predictions
                is_updated = True
                
        
        return {
            'inference_result': inference_result,
            'stable_result': self.stable_result,
            'is_updated': is_updated,
            'stability_info': stability_info
        }
    
    def _check_stability(self):
        """
        äºˆæ¸¬ã®å®‰å®šæ€§ã‚’ãƒã‚§ãƒƒã‚¯
        
        Returns:
            tuple: (is_stable: bool, stability_info: dict)
        """
        if len(self.prediction_history) < self.stability_window:
            return False, {
                'status': 'insufficient_data',
                'window_filled': len(self.prediction_history),
                'required': self.stability_window
            }
        
        # æœ€æ–°ã®Nå€‹ã®äºˆæ¸¬ãŒå…¨ã¦åŒã˜ã‚¯ãƒ©ã‚¹ã‹ãƒã‚§ãƒƒã‚¯
        recent_classes = [pred['class'] for pred in self.prediction_history]
        unique_classes = set(recent_classes)
        
        if len(unique_classes) == 1:
            # å…¨ã¦åŒã˜ã‚¯ãƒ©ã‚¹
            stable_class = recent_classes[0]
            avg_confidence = np.mean([pred['confidence'] for pred in self.prediction_history])
            
            return True, {
                'status': 'stable',
                'stable_class': stable_class,
                'window_size': len(recent_classes),
                'average_confidence': avg_confidence,
                'confidence_std': np.std([pred['confidence'] for pred in self.prediction_history])
            }
        else:
            # ã¾ã ä¸å®‰å®š
            return False, {
                'status': 'unstable',
                'unique_classes': list(unique_classes),
                'class_counts': {cls: recent_classes.count(cls) for cls in unique_classes},
                'window_size': len(recent_classes)
            }
    
    def get_current_stable_class(self):
        """ç¾åœ¨ã®å®‰å®šã—ãŸã‚¯ãƒ©ã‚¹ã‚’å–å¾—"""
        return {
            'stable_class': self.stable_class,
            'stable_confidence': self.stable_confidence,
            'stable_result': self.stable_result
        }
    
    def get_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        stability_rate = self.stable_updates / max(self.total_predictions, 1) * 100
        
        return {
            'total_predictions': self.total_predictions,
            'stable_updates': self.stable_updates,
            'stability_rate': stability_rate,
            'last_update_step': self.last_update_step,
            'current_stable_class': self.stable_class,
            'window_size': self.stability_window
        }
    
    def visualize_stability_stats(self):
        """å®‰å®šæ€§çµ±è¨ˆã®å¯è¦–åŒ–"""
        stats = self.get_statistics()
        
        print(f"\nğŸ“Š Stability Statistics:")
        print(f"   Total Predictions: {stats['total_predictions']}")
        print(f"   Stable Updates: {stats['stable_updates']}")
        print(f"   Stability Rate: {stats['stability_rate']:.1f}%")
        print(f"   Current Stable Class: {stats['current_stable_class']}")
        print(f"   Last Update Step: {stats['last_update_step']}")
        print(f"   Window Size: {stats['window_size']}")