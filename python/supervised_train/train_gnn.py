import torch
from torch.utils.data import DataLoader
import os
import hydra
from omegaconf import DictConfig, OmegaConf

from src.models.models import load_gnn_model
from src.data.dataset.lidar_dataset import LidarSeqDataset
from src.data.dataset.transform import E2ESeqTransform
from src.data.graph.graph import build_batch_graph_cuda
from src.utils.timers import Timer

@hydra.main(config_path="config", config_name="train_gnn", version_base="1.2")
def main(cfg: DictConfig) -> None:
    """
    Hydraã«ã‚ˆã£ã¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€GNNãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’è¡Œã†ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚
    æ™‚ç³»åˆ—ãƒ»éæ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã‚’å˜ä¸€ã®ãƒ­ã‚¸ãƒƒã‚¯ã§æ‰±ã†ã€‚
    """
    print("--- Configuration ---")
    print(OmegaConf.to_yaml(cfg))
    print("---------------------")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # --- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç­‰ã®è¨­å®š ---
    sequence_length = cfg.sequence_length
    batch_size = cfg.batch_size
    num_epochs = cfg.num_epochs
    lr = cfg.lr
    early_stop_epochs = cfg.early_stop_epochs
    
    # --- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™ ---
    data_path = hydra.utils.to_absolute_path(cfg.data_path)
    transform = E2ESeqTransform(range_max=cfg.range_max, base_num=1081, downsample_num=cfg.input_dim)
    train_dataset = LidarSeqDataset(root_dir=data_path, sequence_length=sequence_length, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    
    # --- ãƒ¢ãƒ‡ãƒ«ã®å‹•çš„ãƒ­ãƒ¼ãƒ‰ ---
    model = load_gnn_model(model_name=cfg.model_name,
                           input_dim=cfg.input_dim,
                           hidden_dim=cfg.hidden_dim,
                           output_dim=cfg.output_dim,
                           pool_method=cfg.pool_method)
    model.to(device)
    print(f"Loaded model: {cfg.model_name}")

    criterion = torch.nn.SmoothL1Loss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # --- ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨Early Stoppingã®æº–å‚™ ---
    patience_counter = 0
    top_k = 3
    top_k_checkpoints = []
    save_path = cfg.ckpt_path
    os.makedirs(save_path, exist_ok=True)
    
    # -------------------
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    # -------------------
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for batch in train_loader:
            scan_seq = batch['scan_seq'].to(device) # [B, T, N]
            
            # ------------------------------------------------------------------
            # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€: å‡¦ç†ã‚’çµ±ä¸€ â˜…â˜…â˜…
            # å¸¸ã«ã‚°ãƒ©ãƒ•ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹ã€‚
            # sequence_length=1 ã®å ´åˆã¯ã€è¦ç´ æ•°1ã®ãƒªã‚¹ãƒˆãŒç”Ÿæˆã•ã‚Œã‚‹ã€‚
            # ------------------------------------------------------------------
            data_sequence = []
            for t in range(scan_seq.size(1)): # scan_seq.size(1) ã¯ sequence_length
                scans_at_t = scan_seq[:, t, :] # æ™‚åˆ»tã®LiDARãƒ‡ãƒ¼ã‚¿ [B, N]
                
                with Timer(timer_name="build_batch_graph_cuda"):
                    graph_batch_at_t = build_batch_graph_cuda(
                        scans_at_t, 
                        distance_threshold=cfg.distance_threshold,
                        max_edges=cfg.max_edges,
                    )
                    data_sequence.append(graph_batch_at_t)

            # ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã¯ã€å¸¸ã«ã‚°ãƒ©ãƒ•ã®ãƒªã‚¹ãƒˆ
            output = model(data_sequence)
            
            # ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«ã®æ¬¡å…ƒæ•°ã«å¿œã˜ã¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å½¢çŠ¶ã‚’å¤‰ãˆã‚‹
            if output.dim() == 3:
                # --- å‡ºåŠ›ãŒ3æ¬¡å…ƒ (B, T, F) ã®å ´åˆ: æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã¨åˆ¤æ–­ ---
                target_steer = batch['steer_seq']
                target_speed = batch['speed_seq']
                target = torch.stack([target_steer, target_speed], dim=2).to(device)
            
            elif output.dim() == 2:
                # --- å‡ºåŠ›ãŒ2æ¬¡å…ƒ (B, F) ã®å ´åˆ: éæ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã¨åˆ¤æ–­ ---
                target_steer = batch['steer_seq'][:, -1]
                target_speed = batch['speed_seq'][:, -1]
                target = torch.stack([target_steer, target_speed], dim=1).to(device)

            else:
                # æƒ³å®šå¤–ã®å½¢çŠ¶ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã™
                raise ValueError(f"Unsupported output shape: {output.shape}")


            # æå¤±è¨ˆç®—ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
            loss = criterion(output, target)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        avg_loss = running_loss / len(train_loader)
        print(f"[Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}")

        # --- ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ & Early Stopping ---
        if len(top_k_checkpoints) < top_k or avg_loss < top_k_checkpoints[-1][0]:
            checkpoint_path = os.path.join(save_path, f'model_epoch_{epoch+1}_loss_{avg_loss:.4f}.pth')
            torch.save(model.state_dict(), checkpoint_path)
            print(f"  [âœ”] Saved new top-k model (loss={avg_loss:.4f})")
            
            top_k_checkpoints.append((avg_loss, epoch + 1, checkpoint_path))
            top_k_checkpoints.sort(key=lambda x: x[0])
            
            if len(top_k_checkpoints) > top_k:
                worst_checkpoint = top_k_checkpoints.pop()
                if os.path.exists(worst_checkpoint[2]):
                    os.remove(worst_checkpoint[2])
                    print(f"  [ğŸ—‘] Removed old model: {os.path.basename(worst_checkpoint[2])}")
            patience_counter = 0
        else:
            patience_counter += 1
            best_loss = top_k_checkpoints[0][0] if top_k_checkpoints else float('inf')
            print(f"  [!] No improvement over best loss ({best_loss:.4f}). Patience: {patience_counter}/{early_stop_epochs}")
            if patience_counter >= early_stop_epochs:
                print("[â¹] Early stopping triggered.")
                break

    print("\n--- Training Finished ---")
    print("Top models saved:")
    for loss_val, epoch_num, path in top_k_checkpoints:
        print(f"  - Epoch: {epoch_num}, Loss: {loss_val:.4f}, Path: {path}")


if __name__ == "__main__":
    main()