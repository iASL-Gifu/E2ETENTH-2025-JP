{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "このノートブックは, [他者のレポジトリ](https://github.com/CL2-UWaterloo/Raceline-Optimization.git)から導入したものです"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Converter\n",
    "This is a Jupyter Notebook to Convert a `.png` or `.pgm` + `.yaml` of a map into a `.csv` that can be fed into the TUMFTM functions.\n",
    "\n",
    "High Level Steps:\n",
    "1. Get the Euclidean Distance Transform of the map\n",
    "2. Apply skeletonization to the map to extract centerlines\n",
    "3. Run DFS to extract the centerline xy coordinates in order\n",
    "4. Apply the transformations to go from pixel to meter coordinate frame\n",
    "\n",
    "\n",
    "Map Conditions:\n",
    "- Map edges should be well defined, inside should be white, walls are black and outside is grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.morphology import skeletonize\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import scipy\n",
    "from scipy.ndimage import distance_transform_edt as edt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拡張子を除いたマップ名を指定してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_NAME = \"Austin_map\"\n",
    "\n",
    "TRACK_WIDTH_MARGIN = 0.0 # Extra Safety margin, in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from https://github.com/CL2-UWaterloo/Head-to-Head-Autonomous-Racing/blob/main/gym/f110_gym/envs/laser_models.py\n",
    "# load map image\n",
    "\n",
    "if os.path.exists(f\"maps/{MAP_NAME}.png\"):\n",
    "    map_img_path = f\"maps/{MAP_NAME}.png\"\n",
    "elif os.path.exists(f\"maps/{MAP_NAME}.pgm\"):\n",
    "    map_img_path = f\"maps/{MAP_NAME}.pgm\"\n",
    "else:\n",
    "    raise Exception(\"Map not found!\")\n",
    "\n",
    "map_yaml_path = f\"maps/{MAP_NAME}.yaml\"\n",
    "raw_map_img = np.array(Image.open(map_img_path).transpose(Image.FLIP_TOP_BOTTOM))\n",
    "raw_map_img = raw_map_img.astype(np.float64)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(raw_map_img, cmap='gray', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の２値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale -> binary. Converts grey to black\n",
    "map_img = raw_map_img.copy()\n",
    "map_img[map_img <= 210.] = 0\n",
    "map_img[map_img > 210.] = 1\n",
    "\n",
    "map_height = map_img.shape[0]\n",
    "# map_width = map_img.shape[1]\n",
    "map_img\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(map_img, cmap='gray', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# Calculate Euclidean Distance Transform (tells us distance to nearest wall)\n",
    "dist_transform = scipy.ndimage.distance_transform_edt(map_img)\n",
    "plt.imshow(dist_transform, cmap='gray', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Threshold the distance transform to create a binary image\n",
    "THRESHOLD = 0.17 # You should play around with this number. Is you say hairy lines generated, either clean the map so it is more curvy or increase this number\n",
    "centers = dist_transform > THRESHOLD*dist_transform.max()\n",
    "centers = centers.astype(np.uint8)  # 0, 1 の値を持つグレースケール画像\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(centers, origin='lower', cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "centerline = skeletonize(centers)\n",
    "centerline = centerline.astype(np.uint8)\n",
    "plt.imshow(centerline, origin='lower', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The centerline has the track width encoded\n",
    "plt.figure(figsize=(10, 10))\n",
    "centerline_dist = np.where(centerline, dist_transform, 0)\n",
    "centerline_dist = np.mean(centerline_dist, axis=2)\n",
    "plt.imshow(centerline_dist, origin='lower', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_START_Y = map_height // 2 - 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_EDGE = 0.0\n",
    "# Use DFS to extract the outer edge\n",
    "left_start_y = LEFT_START_Y\n",
    "left_start_x = 0\n",
    "print(centerline_dist.shape)\n",
    "while (centerline_dist[left_start_y][left_start_x] == NON_EDGE): \n",
    "\tleft_start_x += 1\n",
    "\n",
    "print(f\"Starting position for left edge: {left_start_x} {left_start_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DFS\n",
    "import sys\n",
    "sys.setrecursionlimit(20000)\n",
    "\n",
    "visited = {}\n",
    "centerline_points = []\n",
    "track_widths = []\n",
    "# DIRECTIONS = [(0, 1), (1, 0), (0, -1), (-1, 0), (1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "# If you want the other direction first\n",
    "DIRECTIONS = [(0, -1), (-1, 0),  (0, 1), (1, 0), (-1, 1), (-1, -1), (1, 1), (1, -1) ]\n",
    "\n",
    "starting_point = (left_start_x, left_start_y)\n",
    "\n",
    "def dfs(point):\n",
    "\tif (point in visited): return\n",
    "\tvisited[point] = True\n",
    "\tcenterline_points.append(np.array(point))\n",
    "\ttrack_widths.append(np.array([centerline_dist[point[1]][point[0]], centerline_dist[point[1]][point[0]]]))\n",
    "\n",
    "\tfor direction in DIRECTIONS:\n",
    "\t\tif (centerline_dist[point[1] + direction[1]][point[0] + direction[0]] != NON_EDGE and (point[0] + direction[0], point[1] + direction[1]) not in visited):\n",
    "\t\t\tdfs((point[0] + direction[0], point[1] + direction[1]))\n",
    "\n",
    "dfs(starting_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## この下のセルで周回方向の確認をしておいてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3, ax4) = plt.subplots(1, 4, figsize=(20,5))\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "ax4.axis('off')\n",
    "\n",
    "centerline_img = np.zeros(map_img.shape)\n",
    "for x,y in centerline_points[:len(centerline_points)//10]:\n",
    "\tcenterline_img[y][x] = 255\n",
    "ax1.imshow(centerline_img, cmap='Greys', vmax=1, origin='lower')\n",
    "ax1.set_title(\"First 10% points\")\n",
    "\n",
    "centerline_img = np.zeros(map_img.shape)\n",
    "for x,y in centerline_points[:len(centerline_points)//4]:\n",
    "\tcenterline_img[y][x] = 255\n",
    "ax2.imshow(centerline_img, cmap='Greys', vmax=1, origin='lower')\n",
    "ax2.set_title(\"First 25% points\")\n",
    "\n",
    "centerline_img = np.zeros(map_img.shape)\n",
    "for x,y in centerline_points[:int(len(centerline_points)/1.4)]:\n",
    "\tcenterline_img[y][x] = 255\n",
    "ax3.imshow(centerline_img, cmap='Greys', vmax=1, origin='lower')\n",
    "ax3.set_title(\"First 50% points\")\n",
    "\n",
    "centerline_img = np.zeros(map_img.shape)\n",
    "for x,y in centerline_points:\n",
    "\tcenterline_img[y][x] = 1000\n",
    "ax4.imshow(centerline_img, cmap='Greys', vmax=1, origin='lower')\n",
    "ax4.set_title(\"All points\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逆だった場合したのセルで反転してください\n",
    "*心配だったら上のセルに戻り反転していることを確認してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centerline_points.reverse()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion\n",
    "Convert into Pandas, and go from pixels to meters, and then shift by the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_widths_np = np.array(track_widths)\n",
    "waypoints = np.array(centerline_points)\n",
    "print(f\"Track widths shape: {track_widths_np.shape}, waypoints shape: {waypoints.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge track with waypoints\n",
    "data = np.concatenate((waypoints, track_widths_np), axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load map yaml\n",
    "with open(map_yaml_path, 'r') as yaml_stream:\n",
    "    try:\n",
    "        map_metadata = yaml.safe_load(yaml_stream)\n",
    "        map_resolution = map_metadata['resolution']\n",
    "        origin = map_metadata['origin']\n",
    "    except yaml.YAMLError as ex:\n",
    "        print(ex)\n",
    "\n",
    "# calculate map parameters\n",
    "orig_x = origin[0]\n",
    "orig_y = origin[1]\n",
    "# ??? Should be 0\n",
    "orig_s = np.sin(origin[2])\n",
    "orig_c = np.cos(origin[2])\n",
    "\n",
    "# get the distance transform\n",
    "transformed_data = data\n",
    "transformed_data *= map_resolution\n",
    "transformed_data += np.array([orig_x, orig_y, 0, 0])\n",
    "\n",
    "# Safety margin\n",
    "transformed_data -= np.array([0, 0, TRACK_WIDTH_MARGIN, TRACK_WIDTH_MARGIN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you get the following error: raise IOError(\"At least two spline normals are crossed, check input or increase smoothing factor!\")\n",
    "# transformed_data = transformed_data[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"maps/{MAP_NAME}.csv\", 'wb') as fh:\n",
    "    np.savetxt(fh, transformed_data, fmt='%0.4f', delimiter=',', header='x_m,y_m,w_tr_right_m,w_tr_left_m')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, check out `sanity_check.ipynb` to make sure that the centerline generated lines up with the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
